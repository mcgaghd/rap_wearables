---
title: "Incident_analysis"
author: "Dylan McGagh"
output: 
---

Load packages for use:
```{r setup, include=FALSE}
library(ggplot2)
library(survival)
library(data.table)
library(lmtest)
library(Epi)
library(gridExtra)
library(Hmisc)

source("rounding_functions.R")
source("cut_by_quantile.R")
source("cox_functions.R")
source("plotting_functions.R")
options(bitmapType='cairo')

dir.create('outputs', showWarnings = FALSE)  
```

```{r}
dat <- fread("prepped_data.csv", data.table = FALSE)  
```

We select the relevant columns for our analysis
```{r}
covariates <- c("sex", "tdi_cats", "smoking", "alcohol")
mediators <- c("BMI_cats", "depression")
out_vars <- c("age_entry_days", "age_exit_days", "PsA_incident")
primary <- c("med_steps")
secondary <- c("CadencePeak1Adjusted.steps.min.", "CadencePeak30Adjusted.steps.min.")

cols <- c(covariates, mediators, out_vars, primary,secondary)

missing_columns <- setdiff(cols, colnames(dat))
if (length(missing_columns) > 0) {
  err_message <- paste("The following columns are not found in the dataset: ", 
                       paste(missing_columns, collapse = ", "))
  stop(err_message)
} else {
  dat <- dat[, cols]
}
```

We divide into categories
```{r}
dat$step_thirds <- qtile_cut(dat[[primary]], probs = seq(0, 1, by = (1/3)))

dat$cadence1_thirds <-qtile_cut(dat$CadencePeak1Adjusted.steps.min., probs = seq(0, 1, by = (1/3)))

dat$cadence30_thirds <-qtile_cut(dat$CadencePeak30Adjusted.steps.min., probs = seq(0, 1, by = (1/3)))

dat$tdi_cats <- 
  factor(dat$tdi_cats,
         levels = c("Least Deprived", "2nd Quintile", "3rd Quintile", "4th Quintile", "Most Deprived"),
         ordered = FALSE)

dat$tdi_

dat$BMI_cats <-
  factor(dat$BMI_cats,
      levels = c("<18.5", "18.5-24.9", "25.0-29.9", "30.0+"),
      ordered = FALSE)

dat$smoking <-
  factor(dat$smoking,
         levels = c("Never", "Previous", "Current"),
         ordered = FALSE)

dat$alcohol <-
  factor(dat$alcohol,
         levels = c("Never", "<3 times/week", "3+ times/week"),
         ordered = FALSE)
```

We then test the departure from linearity for each of the relevant covariates

1. Steps
If the p value is < 0.05, it means we cannot use this variable as continuous.
```{r}
# Perform the likelihood ratio test
modelA <- coxph(as.formula(paste("Surv(", paste(out_vars, collapse = ", "), 
                                 ") ~ as.numeric(step_thirds) + factor(sex)")), 
                data = dat)

modelB <- coxph(as.formula(paste("Surv(", paste(out_vars, collapse = ", "), 
                                 ") ~ as.factor(step_thirds) + factor(sex)")), 
                data = dat)

lr_test <- lmtest::lrtest(modelA, modelB)

print(lr_test)
```

CadenceModels
We have departure from linearity in Cadence1 - however we can use Cadence30 
```{r}
modelCadence30A <- coxph(as.formula(paste("Surv(", paste(out_vars, collapse = ", "), 
                                 ") ~ as.numeric(cadence30_thirds) + factor(sex)")), 
                data = dat)

modelCadence30B <- coxph(as.formula(paste("Surv(", paste(out_vars, collapse = ", "), 
                                 ") ~ as.factor(cadence30_thirds) + factor(sex)")), 
                data = dat)

lr_testCadence30 <- lmtest::lrtest(modelCadence30A, modelCadence30B)

print(lr_testCadence1)
```

```{r}
dat$std_steps <- standardise_column(dat[[primary]], 1000, TRUE)
```
```{r}
dat$std_cadence30 <- standardise_column(dat$CadencePeak30Adjusted.steps.min., 3, TRUE)
```

We confirm the proportional hazards assumption

```{r}
# Proportional Hazard Model
formula <- as.formula(paste("Surv(", paste(out_vars, collapse = ", "), ") ~ std_cadence30 +", 
                            paste(c(covariates, mediators), collapse = "+")))

model_ph_test <- coxph(formula, data = dat)

summary(model_ph_test)

hazards_table <- cox.zph(model_ph_test)
print(hazards_table)

# Schoenfeld Residuals Plot
for (i in seq_along(c(covariates, mediators, "std_steps"))) {
  # Create a Schoenfeld Residuals Plot for the i-th variable
  plot(hazards_table, var = i, main = "Schoenfeld Residual Plot")
  abline(h = coef(model_ph_test)[2], lty = 2, col = "red")
}
```

PH assumption for Cadence 30
```{r}
# Proportional Hazard Model
formula <- as.formula(paste("Surv(", paste(out_vars, collapse = ", "), ") ~ std_cadence30 +", 
                            paste(c(covariates, mediators), collapse = "+")))

model_ph_test <- coxph(formula, data = dat)

summary(model_ph_test)

hazards_table <- cox.zph(model_ph_test)
print(hazards_table)

# Schoenfeld Residuals Plot
for (i in seq_along(c(covariates, mediators, "std_steps"))) {
  # Create a Schoenfeld Residuals Plot for the i-th variable
  plot(hazards_table, var = i, main = "Schoenfeld Residual Plot")
  abline(h = coef(model_ph_test)[2], lty = 2, col = "red")
}
```

## Shape plot

```{r}
exposures <- c("std_cadence30")

outcomes <- c(out_vars[length(out_vars)])

adjustments <- list(
  "min_model" = c("sex"),
  "max_model" = covariates
)

for (exposure in exposures) {
  # SET UP RECORDING FRAME ======================================================
  results_columns <-   c("Exposure",
                         "Outcome",
                         "Model",
                         "Adjustment",
                         "n",
                         "n_event",
                         as.vector(outer(
                           # excessively complex code to get crossed column names
                           c(
                             "HR",
                             "Lower_CI",
                             "Upper_CI",
                             "floatedlnHR",
                             "floatedSE",
                             "floatedHR",
                             "floatedLower_CI",
                             "floatedUpper_CI",
                             "n",
                             "n_event", 
                             "mean_steps"
                           ),
                           unique(dat[, exposure]),
                           paste,
                           sep = "_"
                         )))
  results_tab <-
    data.frame(matrix(ncol = length(results_columns) ,
                      nrow = 0))
  colnames(results_tab) <- results_columns
  
  # Do modelling: ===============================================================
  for (i in 1:length(outcomes)) {
    for (j in 1:length(adjustments)) {
      # Pull relevant values-----------------------------
      outcome <- outcomes[i]
      model_name <- names(adjustments)[j]
      covs <- adjustments[[j]]
      
      # Organise for model calculation-------------------
      cov_sum <- paste0(c(exposure, covs), collapse = "+")
      
      # Model--------------------------------------------
      form <-
        paste0("Surv(age_entry_days, age_exit_days, ",
               outcome,
               ") ~ ",
               cov_sum)
      model <-
        coxph(as.formula(form), dat)
      print(cox.zph(model))
      
      # Extract values-----------------------------------
      results_frame <-
        data.frame(
          "Exposure" = exposure,
          "Outcome" = outcome,
          "Model" = model_name,
          "Adjustment" = paste0(covs, collapse = ","),
          "n" = model$n,
          "n_event" = model$nevent
        )
      
      # CYCLE THROUGH EXPOSURE LEVELS EXTRACTING INFO=============================================
      fac_levels <- levels(factor(dat[, exposure]))
      for (cat in fac_levels) {
        
        # HRs=====================================================================================
        if (cat == fac_levels[1]) {
          HRs <- data.frame(matrix(c(1, 1, 1), nrow = 1))
        }
        else {
          HRs <-
            summary(model)$conf.int[paste0(exposure, cat), c("exp(coef)", "lower .95", "upper .95"), drop = FALSE]
          rownames(HRs) <- NULL
        }
        colnames(HRs) <-
          as.vector(outer(c("HR", "Lower_CI", "Upper_CI"), cat, paste, sep = "_"))
        
        # FLOATED HRs etc =======================================================================
        float_model <- Epi::float(model)# This is doing floating absolute risks using Epi package
        
        
        ## Values
        zval <- qnorm(0.975)
        se <- sqrt(float_model$var[cat])
        lnhr <- float_model$coef[cat]
        
        # Collate into frame
        HRs_floated <-
          data.frame(matrix(c(
            lnhr,
            se,
            exp(lnhr),
            exp(lnhr - se[cat] * zval),
            exp(lnhr + se[cat] * zval)
          ), nrow = 1))
        colnames(HRs_floated) <-
          as.vector(outer(
            c(
              "floatedlnHR",
              "floatedSE",
              "floatedHR",
              "floatedLower_CI",
              "floatedUpper_CI"
            ),
            cat,
            paste,
            sep = "_"
          ))
    
        # n and nevent ===================================================================================
        n_group <- nrow(dat[dat[, exposure] == cat, ])
        n_event_group <- nrow(dat[(dat[, exposure] == cat) & (dat[, outcome]), ])
        n_by_group <- data.frame(matrix(c(n_group, n_event_group), nrow = 1))
        colnames(n_by_group) <-
          as.vector(outer(c("n", "n_event"), cat, paste, sep = "_"))
        
        # Mean exposure ==================================================================================
        col_steps <- paste0("mean_steps_", cat)
        mean_exposure <- data.frame(mean(dat[dat[, exposure] == cat, primary]))
        colnames(mean_exposure) <- c(col_steps)
        
        # Bind together in final data frame ==============================================================
        results_frame <-
          cbind(results_frame, HRs, HRs_floated, n_by_group, mean_exposure)
      }
      
      
      # CHECK THAT n and n events match by different routes
      nsum <- sum(results_frame[,  as.vector(outer(c("n"), fac_levels, paste, sep = "_"))])
      n_eventsum <- sum(results_frame[,  as.vector(outer(c("n_event"), fac_levels, paste, sep = "_"))])
      if ((results_frame$n != nsum)|(results_frame$n_event != n_eventsum)){
        stop("Mismatch between numbers derived from different sources. Recheck model. May be that some rows are being excluded due to missing covariate data.")
      }
      
      
      # BIND INTO FINAL RESULTS FRAME AND DELETE
      results_tab <- rbind(results_tab, results_frame)
      
      rm(results_frame)
      
    }
  }
  
  assign(paste0(exposure, "_results_tab"), results_tab)
  write.csv(results_tab, paste0("outputs/", exposure, "_tab.csv"))
  # print(results_tab)
  rm(results_tab, results_columns)
}

```
```{r}
cadence30_thirds_tab <- fread("outputs/cadence30_thirds_tab.csv")
```

```{r}
step_thirds_tab <- fread("outputs/step_thirds_tab.csv", data.table = FALSE) 
```

Organise results to plot and iteratively produce shape plots with different settings:

```{r}
adjustments <- unique(cadence30_thirds_tab$Adjustment)

# CYCLE OVER ADJUSTMENTS=========================================
for (adjustment in adjustments) {
   
  # CYCLE OVER OUTCOMES ============================
  for (outcome in outcomes) {

    # PROCESS OUTCOME NAME ======================================
    if (outcome == "PsA_incident") {
      outcome_title <- "Incident PsA"
    } else {
      print(outcome)
      stop("Unrecognised outcome value")
    }
   
    # CYCLE OVER EXPOSURES =================================================
    for (exposure in exposures) {
        
      # PROCESS EXPOSURE NAME ==========================================
      if (exposure == "cadence30_thirds") {
        exposure_title <- "Cadence30"
      } else {
        stop("Unrecognised exposure value")
      }
    
      # GET RELEVANT DATASET =================================================
      tab <- get(paste0(exposure, "_results_tab"))
  
      # EXTRACT RELEVANT ELEMENTS OF DATASET=============================
      rel_tab <- tab[(tab$Outcome == outcome) & (tab$Adjustment == adjustment), , drop = FALSE]
      
      cols <- colnames(tab)[grepl("floatedlnHR_", colnames(tab))]
      cats <- sub("floatedlnHR_", "", cols)
        
      fp_frame <-
        data.frame(
          "exposure" = rep(exposure_title, length(cats)),
          "variable" = cats,
          "estimate" = rep(NA, length(cats)),
          "stderr" = rep(NA, length(cats)),
          "n" = rep(NA, length(cats)),
          "n_event" = rep(NA, length(cats))
        )

      for (cat in cats){
        fp_frame[fp_frame$variable == cat, 
                 c("estimate", "stderr", "n", "n_event", "mean_steps")] <- 
          rel_tab[, as.vector(outer(
            c(
              "floatedlnHR",
              "floatedSE",
              "n", 
              "n_event",
              
          
            ),
            cat,
            paste,
            sep = "_"
          ))]
      }

      fp_frame$nlab <- format_thousand(fp_frame$n_event)
      fp_frame$estlab <- round_2_dp(exp(fp_frame$estimate))
      assign(paste0("fp_frame_", exposure, "_", outcome), fp_frame)
    }
  } 

  shapeplot1 <- shape_plot(fp_frame_cadence30_thirds_PsA_incident, display_plot = FALSE)
  assign(paste0("shapeplot_cadence30_thirds_", gsub(",", "_", adjustment)), shapeplot1)
}
```

```{r fig.width=12, fig.height=8}
g <- grid.arrange(shapeplot_step_thirds_sex + ggtitle("Minimally Adjusted"),
                  shapeplot_step_thirds_sex_ethnicity_TDI_cats_smoking_alcohol + 
                    ggtitle("Multivariably Adjusted"), ncol=2,
                  bottom = paste0("Main analysis investigating the association",
                                  " between step tertiles\n and incident",
                                  " Parkinson's disease"))

ggsave(file = 'outputs/shape_plot_main.png', plot = g, width = 12, height = 8, dpi = 600)
```

Next we perform sequential adjustment.

## Sequential adjustment plot

```{r}
label(dat$sex)                  <- "Sex"
label(dat$alcohol)              <- "Alcohol"
label(dat$smoking)              <- "Smoking"
label(dat$tdi_cats)             <- "Townsend Deprivation"
label(dat$depression)           <- "Depression"
label(dat$BMI_cats)             <- "Body Mass Index"
```

```{r, warning=FALSE}
results_list <- list()

results_list[[1]] <- coxph_analysis(dat, "Univariable association", list(), 
                                    primary, out_vars[length(out_vars)], 1000, 
                                    calculate_chi_squared = TRUE)

for (i in seq_along(covariates)) {
  results_list[[i + 1]] <- coxph_analysis(dat, paste0("  + ", label(dat[[covariates[i]]])),
                                          covariates[1:i],primary, out_vars[length(out_vars)], 
                                          1000, calculate_chi_squared = TRUE)
}

covar_adjustments <- do.call(rbind, results_list)

covar_adjustments$Variable <- factor(covar_adjustments$Variable, 
                                     levels = rev(unique(covar_adjustments$Variable)))
```

```{r}
covar_plot <- adjustment_plot(covar_adjustments, save_plot = "outputs/covariate_adjustment.png")
```

```{r}
results_list <- list()

results_list[[1]] <- coxph_analysis(dat, "Multivariable association", covariates, 
                                    primary, out_vars[length(out_vars)], 1000, 
                                    calculate_chi_squared = TRUE)

for (i in seq_along(mediators)) {
  variables <- c(covariates, mediators[i])
  results_list[[i + 1]] <- coxph_analysis(dat, paste0("  + ", label(dat[[mediators[i]]])), 
                                          c(covariates, mediators[i]), primary, 
                                          out_vars[length(out_vars)], 1000, 
                                          calculate_chi_squared = TRUE)
}

# Combine the results into a single data frame
mediator_adjustments <- do.call(rbind, results_list)

mediator_adjustments$Variable <- factor(mediator_adjustments$Variable, 
                                        levels = rev(unique(mediator_adjustments$Variable)))
```

```{r}
mediator_plot <- adjustment_plot(mediator_adjustments, save_plot = "outputs/mediator_analysis.png")
```


# Clear up some of the mess ahead of running future scripts
```{r}
rm(list = setdiff(ls(), lsf.str()))
```